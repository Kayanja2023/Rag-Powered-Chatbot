# Evaluation: Responses Using Vector Database (RAG)

This file documents chatbot responses enriched by FAISS-based retrieval from the knowledge base.

---

## Query 1: What is LangChain?

**Bot Response:**
> LangChain is a framework for developing applications powered by language models.  
> It provides modular abstractions to simplify chaining LLMs with memory, APIs, and knowledge bases.

**Source Context Retrieved:**
> "LangChain is a framework for developing applications powered by language models..."

---

## ✅ Query 2: What is FAISS used for?

**Bot Response:**
> FAISS (Facebook AI Similarity Search) is a library used to store and search vector embeddings efficiently.  
> It enables high-speed similarity search across large collections of embedded documents.

**Source Context Retrieved:**
> "FAISS (Facebook AI Similarity Search) is an efficient library for vector similarity search at scale..."

---

## ✅ Query 3: What are embeddings?

**Bot Response:**
> Embeddings are dense vector representations of text that allow models to compare semantic similarity.  
> They’re crucial for vector search and retrieval in modern NLP systems.

**Source Context Retrieved:**
> "Embeddings are dense vector representations of text. Using models like MiniLM or BERT..."

---

## ✅ Query 4: How does retrieval-augmented generation work?

**Bot Response:**
> Retrieval-Augmented Generation (RAG) combines a vector search step with a language model to provide more accurate and contextual responses.  
> It retrieves relevant chunks from a knowledge base and includes them in the prompt sent to the model.

**Source Context Retrieved:**
> "Retrieval-Augmented Generation (RAG) combines information retrieval with generative models..."

---

